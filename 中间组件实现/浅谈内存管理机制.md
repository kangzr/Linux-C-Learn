> 本文主要介绍内存管理机制，以及各种优秀开源框架采用的内存管理方法

内存管理的目的：提高内存使用率，避免内存泄漏，减少内存碎片，减少内存分配的系统调用。

内存管理可分为操作系统层面和用户层面。接下来会首先介绍操作系统的内存管理，再介绍一些开源框架是如何进行内存管理的。



#### 一. 物理内存与虚拟内存

程序要加载到物理内存才能运行，单核时代程序员是直接操作物理内存的，随着多核时代的到来，会出现多个进程同时操作同一物理内存地址的情况，造成混乱和程序崩溃。因此引入了虚拟内存，程序不再直接操作物理内存，只能看到虚拟内存，通过虚拟内存的概念非常优雅的把进程环境隔离开来。每个进程都拥有自己独立的虚拟地址空间，且地址大小范围完全一样，这给程序编码带来了很大的便利。

##### 那么，物理内存和虚拟内存之间是什么样的关系呢？

虚拟内存以页为单位进行划分，每个页对应物理内存上的页框（通常大小为4KB），MMU（内存管理单元）负责将虚拟地址转换为物理地址，MMU中有一张页表来存储这些映射关系。但并不是虚拟内存的所有页都会分配对应的物理内存，为了充分利用物理内存，保证更多进程运行在操作系统上，尽可能把要用到的页放到内存里，其它基本不用或者很少用的虚拟页则不给它分配物理内存，而是把相关内容存在磁盘上。那如果访问的虚拟内存，通过MMU并没有找到与之对应的物理内存怎么办呢？操作系统会触发缺页中断，从磁盘中取得所缺的页并将其换入物理内存，并在页表建立虚拟页和物理页的映射关系，如果物理内存满了，操作系统就会根据某种页面置换算法（比如LRU算法），将物理内存中对应的页换出到磁盘。（这里需要注意的是，如果被换出的物理内存被修改过，必须把它写回磁盘以更新对应的副本，否则不需要写回）。因此虚拟内存是可以远远大于物理内存的。(整张物理内存和虚拟内存的映射图)

TLB(Translation Lookaside Buffer)：缓存虚拟地址到物理地址的映射关系（因为CPU和物理内存之间速度差距大），作为cache加快访问，而不需要每次地址转换都访问内存，加速转换过程



#### 二. Linux内存管理机制

##### 1. 物理页与进程地址空间

linux内核用`struct page`结构体表示物理页

```c
// include/linux/mm.h
struct page {
    unsigned long flags;  // 页标识符
    atomic_t count;  // 页引用计数
    struct list_head list;  // 页链表
    struct address_space *mapping;  // 所属的inode
    unsigned long index;  // mapping中的偏移
    struct list_head lru;  // 最近最久未使用, struct slab结构指针链表头变量
    void *virtual;  // 页虚拟地址
}
```

进程地址空间分为内核空间(3G到4G)和用户空间(0到3G); (整张进程地址空间图). 每个进程都对应一个`mm_struct`结构体,即唯一的进程地址空间

```c
// include/linux/mm.h
struct vm_area_struct {
    struct mm_struct * vm_mm;
};


// include/linux/sched.h
struct mm_struct {
    struct vm_area_struct *mmap;  // vma链表结构
    struct rb_root mm_rb;   // 红黑树指针
    struct vm_area_struct *mmap_cache;  // 指向最近找到的虚拟区间
    atomic_t mm_users;  // 正在使用该地址的进程数
    atomic_t mm_count;  // 引用计数，为0时销毁
    struct list_head mmlist;  // 所有mm_struct结构体都通过mmlist连接在一个双向链表中
};
```



##### 2. 内存分配

内核通过`brk`和`mmap`来分配（虚拟）内存，`malloc/free`底层实现即为`brk`, `mmap`和`unmmap`

`brk`是通过将数据段(.data)的地址指针`_edata`往高地址推来分配内存，当malloc内存小于128k时采用；`brk`分配的内存需要高地址内存全部释放后才会释放，当最高地址空间空闲内存大于128K时，执行内存紧缩操作。

`mmap`是在堆栈中间的文件映射区域找空闲虚拟内存，当malloc内存大于128K时采用；`mmap`分配的内存可单独释放



##### 3. 内部碎片和外补碎片

- 内部碎片

  原因：分配的内存空间大于请求所需的内存空间，造成内存碎片

  解决：伙伴算法；

  伙伴算法主要包括内存分配和释放两步：

  - 内存分配：需要满足两个条件：1.必须大于请求的内存大小；2. 必须是最小内存块（比如64K）的倍数；比如最小内存块为64K，如果分配100K，那么分配的块大小为64*2=128K。
  - 内存释放：分为两步，1. 释放内存，2. 检查是否可以和相邻块合并，直到没有可合并的内存块

  

  接下来通过一张图来说明伙伴算法的原理， 以下是wiki中截图的一张图，共1024KB，最小分配内存块为64KB，伙伴算法步骤如下：

  1. 初始化内存，分配1024KB

  2. A申请34K的内存，因此需要分配给64K的块

     2.1 2.2 2.3 2.4：全部执行对半分操作

     2.5：找到满足条件的块，进行内存块

  3. B申请66K内存，因此需要分配128K的块，由现成的直接分配

  4. C申请35K内存，需要64K的块，直接分配

  5. D申请67K内存，需要128K的块

     5.1：对半分(黄色)

     5.2：分配128K

  6. 释放B内存块，没有相邻的内存可以合并

  7. 释放D内存块

     7.1：释放内存

     7.2：与相邻内存合并

  8. A释放内存，没有相邻的内存可合并

  9. C释放内存

     9.1：释放内存

     9.2-9.5：进行合并

  ![buddy_m](..\pic\buddy_m.png)

  理解了伙伴算法的原理后，可以考虑用完全二叉树来实现一个伙伴算法，可以参考[云风的伙伴算法实现](https://github.com/cloudwu/buddy.git)，通过一个数组实现一个二叉树，来记录和管理内存块

  

- 外部碎片

  原因：未被分配的内存，出现大量零碎不连续小内存，无法满足较大内存申请，造成外部碎片

  解决：slab分配器



















C++内存管理

golang内存管理

go allocator go的内存分配是从tcmalloc发展而来，基本思想一致

golang编译器根据一个变量是否会在定义的作用域外被引用来决定把这个变量分配在栈上还是堆上

go是带gc（garbage collection）功能的语言，即使在堆上分配的变量也不需要程序员释放内存，也能保证使用变量的安全性；逃逸分析和垃圾回收

ringbuffer：

例子来源于网络服务提供程序的一个普遍场景：一个服务器程序收到客户端的网络数据流，在这个数据流上会有很多个独立的数据包，只有一个数据包接收完整了才能做进一步的处理。如果在一个网络连接上数据包并不完整，就需要暂时缓存住尚未接收完的数据包

#### tcmalloc